{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure,show\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.image import RecurrencePlot\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout,InputLayer,Dropout\n",
    "from keras import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attack_free,data_spoofing_attack,data_fuzzy_attack,data_DoS_attack=[],[],[],[]\n",
    "with open(\"D:\\IIT-Delhi\\Semester-2\\SIL765-Networks & System Security\\Project\\Implementation\\DataSets\\Attack_free_dataset.txt\") as f_a:\n",
    "    data_attack_free.extend([re.sub(r\"Timestamp:\\s+(\\d+\\.\\d+)\\s+ID:\\s+([\\da-f]{4})\\s+\\d+\\s+DLC:\\s+\\d+(\\s+[\\da-f]{2})*\", r\"\\1@\\2\", lines).strip(\"\\n\").split(\"@\") for lines in f_a.readlines()])\n",
    "\n",
    "with open(\"D:\\IIT-Delhi\\Semester-2\\SIL765-Networks & System Security\\Project\\Implementation\\DataSets\\Impersonation_attack_dataset.txt\") as f_b:\n",
    "    data_spoofing_attack.extend([re.sub(r\"Timestamp:\\s+(\\d+\\.\\d+)\\s+ID:\\s+([\\da-f]{4})\\s+\\d+\\s+DLC:\\s+\\d+(\\s+[\\da-f]{2})*\", r\"\\1@\\2\", lines).strip(\"\\n\").split(\"@\") for lines in f_b.readlines()])\n",
    "\n",
    "with open(\"D:\\IIT-Delhi\\Semester-2\\SIL765-Networks & System Security\\Project\\Implementation\\DataSets\\Fuzzy_attack_dataset.txt\") as f_c:\n",
    "    data_fuzzy_attack.extend([re.sub(r\"Timestamp:\\s+(\\d+\\.\\d+)\\s+ID:\\s+([\\da-f]{4})\\s+\\d+\\s+DLC:\\s+\\d+(\\s+[\\da-f]{2})*\", r\"\\1@\\2\", lines).strip(\"\\n\").split(\"@\") for lines in f_c.readlines()])\n",
    "\n",
    "with open(\"D:\\IIT-Delhi\\Semester-2\\SIL765-Networks & System Security\\Project\\Implementation\\DataSets\\DoS_attack_dataset.txt\") as f_d:\n",
    "    data_DoS_attack.extend([re.sub(r\"Timestamp:\\s+(\\d+\\.\\d+)\\s+ID:\\s+([\\da-f]{4})\\s+\\d+\\s+DLC:\\s+\\d+(\\s+[\\da-f]{2})*\", r\"\\1@\\2\", lines).strip(\"\\n\").split(\"@\") for lines in f_d.readlines()])\n",
    "a_id_attack_free,a_id_spoofing_attack,a_id_fuzzy_attack,a_id_DoS_attack=[],[],[],[]\n",
    "for i in range(len(data_attack_free)):\n",
    "    a_id_attack_free.append(str(data_attack_free[i][1]))\n",
    "for i in range(len(data_spoofing_attack)):\n",
    "    a_id_spoofing_attack.append(str(data_spoofing_attack[i][1]))\n",
    "for i in range(len(data_fuzzy_attack)):\n",
    "    a_id_fuzzy_attack.append(str(data_fuzzy_attack[i][1]))\n",
    "for i in range(len(data_DoS_attack)):\n",
    "    a_id_DoS_attack.append(str(data_DoS_attack[i][1]))\n",
    "a1,a2,a3,a4=[],[],[],[]\n",
    "for hex_num in a_id_attack_free:\n",
    "    dec_value = int(hex_num, 16)\n",
    "    a1.append(dec_value)\n",
    "for hex_num in a_id_spoofing_attack:\n",
    "    dec_value = int(hex_num, 16)\n",
    "    a2.append(dec_value)\n",
    "for hex_num in a_id_fuzzy_attack:\n",
    "    dec_value = int(hex_num, 16)\n",
    "    a3.append(dec_value)\n",
    "for hex_num in a_id_DoS_attack:\n",
    "    dec_value = int(hex_num, 16)\n",
    "    a4.append(dec_value)\n",
    "range1=int(np.floor(len(a1)/(128*128)))\n",
    "range2=int(np.floor(len(a2)/(128*128)))\n",
    "range3=int(np.floor(len(a3)/(128*128)))\n",
    "range4=int(np.floor(len(a4)/(128*128)))\n",
    "storage=np.array([])\n",
    "rp = RecurrencePlot(dimension=1,threshold='point',percentage=40)\n",
    "temp1=[]\n",
    "count=0\n",
    "for i in range(range1):\n",
    "    temp=np.array(a1[(i*(128**2)):((i+1)*(128**2))])\n",
    "    temp=temp.reshape(128,128)\n",
    "    plot = rp.fit_transform(temp)\n",
    "    plot=np.array(plot[0])\n",
    "    plot=plot.astype(int)\n",
    "    storage=np.append(values=plot,arr=storage)\n",
    "    storage=storage.reshape(count+1,128,128,1)\n",
    "    count=count+1\n",
    "for i in range(range2):\n",
    "    temp=np.array(a2[(i*(128**2)):((i+1)*(128**2))])\n",
    "    temp=temp.reshape(128,128)\n",
    "    plot = rp.fit_transform(temp)\n",
    "    plot=np.array(plot[0])\n",
    "    plot=plot.astype(int)\n",
    "    storage=np.append(values=plot,arr=storage)\n",
    "    storage=storage.reshape(count+1,128,128,1)\n",
    "    count=count+1\n",
    "for i in range(range3):\n",
    "    temp=np.array(a3[(i*(128**2)):((i+1)*(128**2))])\n",
    "    temp=temp.reshape(128,128)\n",
    "    plot = rp.fit_transform(temp)\n",
    "    plot=np.array(plot[0])\n",
    "    plot=plot.astype(int)\n",
    "    storage=np.append(values=plot,arr=storage)\n",
    "    storage=storage.reshape(count+1,128,128,1)\n",
    "    count=count+1\n",
    "for i in range(range4):\n",
    "    temp=np.array(a4[(i*(128**2)):((i+1)*(128**2))])\n",
    "    temp=temp.reshape(128,128)\n",
    "    plot = rp.fit_transform(temp)\n",
    "    plot=np.array(plot[0])\n",
    "    plot=plot.astype(int)\n",
    "    storage=np.append(values=plot,arr=storage)\n",
    "    storage=storage.reshape(count+1,128,128,1)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=storage\n",
    "y=np.array([])\n",
    "y=np.append(values=[0]*range1,arr=y)\n",
    "y=np.append(values=[1]*(range2+range3+range4),arr=y)\n",
    "y=y.astype(int)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\",input_shape=(128,128,1)))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2),padding=\"valid\",strides=2))\n",
    "# model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2),padding=\"valid\",strides=2))\n",
    "# model.add(Dropout(0.9))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(units=16,activation=\"relu\"))\n",
    "# model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "# adam = Adam(learning_rate=0.0001)\n",
    "# model.compile(optimizer=adam,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 04s]\n",
      "accuracy: 0.572139322757721\n",
      "\n",
      "Best accuracy So Far: 0.572139322757721\n",
      "Total elapsed time: 00h 03m 14s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     padding=\"same\",activation=\"relu\",\n",
    "                     input_shape=(128,128,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                           padding=\"valid\",\n",
    "                           strides=2))\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3,3),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),\n",
    "                           padding=\"valid\",\n",
    "                           strides=2))\n",
    "    model.add(Dropout(0.9))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=16,                   \n",
    "                    activation=\"relu\"))\n",
    "    for i in range(hp.Int('num_layers',\n",
    "                          min_value=8,\n",
    "                          max_value=16)):\n",
    "        model.add(Dense(hp.Int('units'+str(i),\n",
    "                               min_value=8,\n",
    "                               max_value=16),\n",
    "                               activation=hp.Choice('activation'+str(i),\n",
    "                                                    values=['relu','tanh','sigmoid'])))\n",
    "        model.add(Dropout(hp.Choice('droput'+str(i),\n",
    "                                    values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n",
    "    model.add(Dense(units=1,\n",
    "                    activation=\"sigmoid\"))\n",
    "    optimizer=hp.Choice('optimizer',\n",
    "                        values=['adam','sgd','rmsdrop','adamw','adadelta',\n",
    "                                'adagrad','adamax','adafactor','nadam','ftrl'])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "    return model\n",
    "tuner=kt.RandomSearch(build_model,objective='accuracy',\n",
    "                      max_trials=3,directory='mydir',project_name=\"final\")\n",
    "tuner.search(X_train,y_train,epochs=5,validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 8,\n",
       " 'units0': 10,\n",
       " 'activation0': 'relu',\n",
       " 'droput0': 0.3,\n",
       " 'units1': 8,\n",
       " 'activation1': 'tanh',\n",
       " 'droput1': 0.2,\n",
       " 'units2': 16,\n",
       " 'activation2': 'tanh',\n",
       " 'droput2': 0.4,\n",
       " 'units3': 8,\n",
       " 'activation3': 'tanh',\n",
       " 'droput3': 0.1,\n",
       " 'units4': 9,\n",
       " 'activation4': 'sigmoid',\n",
       " 'droput4': 0.9,\n",
       " 'units5': 16,\n",
       " 'activation5': 'sigmoid',\n",
       " 'droput5': 0.7,\n",
       " 'units6': 8,\n",
       " 'activation6': 'tanh',\n",
       " 'droput6': 0.2,\n",
       " 'units7': 10,\n",
       " 'activation7': 'sigmoid',\n",
       " 'droput7': 0.6,\n",
       " 'optimizer': 'adam',\n",
       " 'units8': 11,\n",
       " 'activation8': 'tanh',\n",
       " 'droput8': 0.4,\n",
       " 'units9': 16,\n",
       " 'activation9': 'sigmoid',\n",
       " 'droput9': 0.2,\n",
       " 'units10': 14,\n",
       " 'activation10': 'relu',\n",
       " 'droput10': 0.3,\n",
       " 'units11': 11,\n",
       " 'activation11': 'tanh',\n",
       " 'droput11': 0.1,\n",
       " 'units12': 14,\n",
       " 'activation12': 'sigmoid',\n",
       " 'droput12': 0.4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 64)      640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 256)       147712    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                4194320   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 81        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                160       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,343,688\n",
      "Trainable params: 4,343,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.7027 - accuracy: 0.5174 - val_loss: 0.6939 - val_accuracy: 0.4783\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 19s 3s/step - loss: 0.7229 - accuracy: 0.4876 - val_loss: 0.6939 - val_accuracy: 0.4783\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.7488 - accuracy: 0.4577 - val_loss: 0.6939 - val_accuracy: 0.4783\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.7198 - accuracy: 0.5025 - val_loss: 0.6939 - val_accuracy: 0.4783\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.7000 - accuracy: 0.5572 - val_loss: 0.6940 - val_accuracy: 0.4783\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.7201 - accuracy: 0.4726 - val_loss: 0.6943 - val_accuracy: 0.4783\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.7233 - accuracy: 0.4975 - val_loss: 0.6944 - val_accuracy: 0.4783\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 26s 4s/step - loss: 0.7459 - accuracy: 0.4179 - val_loss: 0.6944 - val_accuracy: 0.4783\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.7239 - accuracy: 0.4677 - val_loss: 0.6946 - val_accuracy: 0.4783\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 31s 4s/step - loss: 0.7083 - accuracy: 0.5423 - val_loss: 0.6945 - val_accuracy: 0.4783\n",
      "2/2 [==============================] - 3s 738ms/step - loss: 0.6961 - accuracy: 0.4464\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
